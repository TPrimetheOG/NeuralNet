# NeuralNet

## Description
  This project is a minimalist yet powerful implementation of a feedforward neural network built entirely from scratch in C++, leveraging the Eigen library for fast and intuitive matrix operations. It covers the fundamental mechanisms of neural networks including forward propagation, backpropagation, and gradient descent — without using any external machine learning frameworks.

The goal is educational: to demystify how neural networks operate under the hood by building every component manually — from layer definitions to the training loop. The network is trained on the MNIST dataset, showcasing how core deep learning principles translate into working code with just matrices and math.

